# 03. 模仿学习 (Imitation Learning) 指南

为了解决强化学习初期探索效率低下的问题（即“随机乱动”阶段），我们引入了 **模仿学习** 模块。通过录制人类高手的操作数据，让模型快速学会基础的游戏理解和操作。

## 1. 核心流程

1.  **录制数据**: 人工操作游戏，记录画面 (State) 和 动作 (Action)。
2.  **行为克隆 (BC)**: 使用监督学习训练一个基础策略网络。
3.  **强化微调**: 将 BC 模型的权重作为 PPO 的初始权重，进行后续训练。

---

## 2. 专家数据录制器 (`main/record_expert.py`)

这是一个用于采集“示教数据”的工具。它会弹出一个窗口显示手机画面，并捕获您的鼠标操作。

### 启动方式
确保手机已连接并开启 USB 调试。

```powershell
python main/record_expert.py
```

### 操作说明
*   **窗口交互**: 
    *   在弹出的 `Expert Recorder` 窗口中，使用鼠标**左键点击**或**拖拽**来模拟手指操作。
    *   脚本会将鼠标在窗口内的相对坐标转换为手机屏幕坐标。
*   **快捷键**:
    *   `r`: **开始/停止 录制**。
        *   按下 `r` 开始：控制台提示 "Recording started..."，画面左上角会出现**红点**。
        *   再次按 `r` 停止：控制台提示 "Recording stopped..."，数据会自动保存。
    *   `q`: **退出程序**。

### 数据存储
录制的数据保存在项目根目录的 `data/expert_data` 下：
*   `ep{id}_{timestamp}.jpg`: 游戏截图（原始画面）。
*   `episode_{id}.json`: 索引文件，记录了每一帧的时间戳以及对应的鼠标动作。

---

## 3. 行为克隆训练器 (`main/train_bc.py`)

在采集了足够的数据（建议至少 3-5 局完整游戏，包含不同场景）后，使用此脚本进行训练。

### 启动方式

```powershell
python main/train_bc.py
```

### 训练细节
*   **输入**: 读取 `data/expert_data` 下的所有 JSON 和图片。
*   **模型**: 使用与 PPO 相同的 `CNNEncoder` 结构，但输出层直接拟合鼠标坐标 (MSE Loss)。
*   **输出**: 训练好的模型权重会保存在 `models/` 目录下，例如 `bc_model_epoch_50.pth`。

### 常见问题
*   **Q: 需要录制多少数据？**
    *   A: 越多越好。对于简单的移动和攻击，几千帧（约几分钟）即可看到效果；若要学会连招，可能需要数万帧。
*   **Q: 录制时卡顿怎么办？**
    *   A: 录制脚本默认每帧都保存图片，如果 I/O 瓶颈导致卡顿，可以尝试降低 Scrcpy 分辨率或修改代码减少采样率。

---

## 4. 下一步：接入 PPO

完成 BC 训练后，您将获得一个已经“会玩”的模型权重。在运行 PPO 训练 (`main/train.py`) 时，可以加载这个权重作为起点：

*(需修改 `main/train.py` 代码以支持加载预训练权重，后续步骤中实现)*

```python
# 伪代码示例
model = ActorCritic(...)
model.load_state_dict(torch.load("models/bc_model_epoch_50.pth"), strict=False)
```
